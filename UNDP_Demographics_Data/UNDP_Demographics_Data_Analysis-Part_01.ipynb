{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNDP_Demographics_Data-Analysis-Part_01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOD+PaCvGxFKPTXr0MBUnUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandoGitHub/ML_Projects/blob/main/UNDP_Demographics_Data/UNDP_Demographics_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "HNu8v-HprdvD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QW-bJuyqnhA",
        "outputId": "2efe7c33-c5ae-46d8-e116-ec128a96b142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-17 19:50:03--  https://raw.githubusercontent.com/fernandoGitHub/MLOPS_GSD/main/MLOP_setup.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176 (2.1K) [text/plain]\n",
            "Saving to: ‘MLOP_setup.py’\n",
            "\n",
            "\rMLOP_setup.py         0%[                    ]       0  --.-KB/s               \rMLOP_setup.py       100%[===================>]   2.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-17 19:50:03 (20.6 MB/s) - ‘MLOP_setup.py’ saved [2176/2176]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/fernandoGitHub/MLOPS_GSD/main/MLOP_setup.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import MLOP_setup\n",
        "\n",
        "MLOP_setup.install_package('TF_DATA_VALIDATION')\n",
        "MLOP_setup.install_package('TF_TRANSFORM')\n",
        "MLOP_setup.install_package('TFX')"
      ],
      "metadata": {
        "id": "itm_AmTlrpfJ",
        "outputId": "25111582-f442-4582-cfd3-23417b7c35c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing tensorflow-data-validation ...\n",
            "Package tensorflow-data-validation has been successfully installed\n",
            "Reloading Packages\n",
            "Installing tensorflow-transform ...\n",
            "Package tensorflow-transform has been successfully installed\n",
            "Reloading Packages\n",
            "Installing tfx ...\n",
            "Package tfx has been successfully installed\n",
            "Reloading Packages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_data_validation as tfdv\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx.types import standard_artifacts\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from google.protobuf.json_format import MessageToDict\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "x_i_KN4KrsT8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLOP_setup.load_and_import_TF_libraries()\n",
        "import numpy as np\n",
        "import TF_pipeline\n",
        "import TF_schema"
      ],
      "metadata": {
        "id": "GkyqtBa1r314",
        "outputId": "b3c9ae6d-0f11-44c5-ed87-4d5571933bed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing wget ...\n",
            "Package wget has been successfully installed\n",
            "Reloading Packages\n",
            "Fetching from GitHub: TF_pipeline.py ...\n",
            "Fetching from GitHub: TF_stat.py ...\n",
            "Fetching from GitHub: TF_transform.py ...\n",
            "Fetching from GitHub: TF_schema.py ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "rHiOu2jysJvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "_RAW_DATA_DIR = './raw_data'\n",
        "_RAW_DATA_ZIP = os.path.join(_RAW_DATA_DIR, 'UNDP_Demographics_Data.zip')\n",
        "\n",
        "if os.path.isdir('./sample_data'):\n",
        "  shutil.rmtree('./sample_data')\n",
        "\n",
        "if not os.path.isdir(_RAW_DATA_DIR):\n",
        "  os.makedirs(_RAW_DATA_DIR)\n",
        "\n",
        "if not os.path.isfile(_RAW_DATA_ZIP):\n",
        "  !wget -O ./raw_data/UNDP_Demographics_Data.zip https://github.com/fernandoGitHub/ML_Projects/raw/main/UNDP_Demographics_Data/data/UNDP_Demographics_Data.zip"
      ],
      "metadata": {
        "id": "BpPOuGqLsMpO",
        "outputId": "a3541a5f-7595-4b84-b190-7196dcfcbbd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-17 19:51:34--  https://github.com/fernandoGitHub/ML_Projects/raw/main/UNDP_Demographics_Data/data/UNDP_Demographics_Data.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fernandoGitHub/ML_Projects/main/UNDP_Demographics_Data/data/UNDP_Demographics_Data.zip [following]\n",
            "--2022-05-17 19:51:34--  https://raw.githubusercontent.com/fernandoGitHub/ML_Projects/main/UNDP_Demographics_Data/data/UNDP_Demographics_Data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44345 (43K) [application/zip]\n",
            "Saving to: ‘./raw_data/UNDP_Demographics_Data.zip’\n",
            "\n",
            "./raw_data/UNDP_Dem 100%[===================>]  43.31K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-05-17 19:51:34 (2.62 MB/s) - ‘./raw_data/UNDP_Demographics_Data.zip’ saved [44345/44345]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_PROCESSED_DATA_DIR = './processed_data'\n",
        "if not os.path.isdir(_PROCESSED_DATA_DIR):\n",
        "  os.makedirs(_PROCESSED_DATA_DIR)"
      ],
      "metadata": {
        "id": "eKR7UKUacIT1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to clean the raw_data directory\n",
        "#shutil.rmtree('./raw_data')"
      ],
      "metadata": {
        "id": "mvy8ZHwtam1n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zip_file_name = _RAW_DATA_ZIP\n",
        "\n",
        "with ZipFile(zip_file_name, 'r') as zip:\n",
        "  # printing all the contents of the zip file\n",
        "  zip.printdir()\n",
        "\n",
        "  # extracting all the files\n",
        "  zip.extractall(_RAW_DATA_DIR)"
      ],
      "metadata": {
        "id": "ViUmSG8LvlOD",
        "outputId": "2e4402a6-6379-451e-ed7b-ca652f7716ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "Median_age.csv                                 2022-05-13 15:11:54         9288\n",
            "Old_age_dependency_ratio.csv                   2022-05-13 15:11:54        14159\n",
            "Population _ages_65 _and _older.csv            2022-05-13 15:11:54        12651\n",
            "Population_ages_15_64.csv                      2022-05-13 15:11:54        14059\n",
            "Population_under_age_5.csv                     2022-05-13 15:11:54        12955\n",
            "Sex_ratio_at_birth.csv                         2022-05-13 15:11:54         9570\n",
            "Total_Population.csv                           2022-05-13 15:11:54        15523\n",
            "Urban_Population.csv                           2022-05-13 15:11:54        16114\n",
            "Young_age_dependency_ratio.csv                 2022-05-13 15:11:54        15756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation"
      ],
      "metadata": {
        "id": "ZkBwhAoMybIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's review the columnns at each dataset"
      ],
      "metadata": {
        "id": "W5JV65Pt6-qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_file_list_from_dir(path, filter = '*.*', display=False):\n",
        "  \"\"\"generate_list_from_dir(path, filter = '*.*', display=False) returns two lists of strings.\n",
        "  The first includes the names of the csv files, the second the full paths. The filter parameter\n",
        "  can be used to return only a given type of files.\n",
        "  By default, the function doesn't filter any file\"\"\"\n",
        "\n",
        "  file_list = os.listdir(path=path)\n",
        "\n",
        "  if filter != '*.*':\n",
        "    file_list = [file for file in file_list if filter in file]\n",
        "\n",
        "  full_path_list = [os.path.join(path, file) for file in file_list]\n",
        "\n",
        "  if display:\n",
        "    print(file_list)\n",
        "\n",
        "  return file_list, full_path_list\n"
      ],
      "metadata": {
        "id": "pIbmb_soYeKG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_list, csv_full_path_list = generate_file_list_from_dir(path=_RAW_DATA_DIR, filter = '.csv', display=False)\n",
        "\n",
        "for file in csv_full_path_list:\n",
        "  temp_df = pd.read_csv(file)\n",
        "  print (f\"csv file: {file} - columns: {temp_df.columns}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJPE7K487EQl",
        "outputId": "c354366a-82bf-4dfb-a26c-33aa37f964f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv file: ./raw_data/Old_age_dependency_ratio.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Young_age_dependency_ratio.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Urban_Population.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population_ages_15_64.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Median_age.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2015',\n",
            "       '2020'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population_under_age_5.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Total_Population.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2030'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Sex_ratio_at_birth.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2015',\n",
            "       '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population _ages_65 _and _older.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding:** We can see some irregularities:\n",
        "   1.- Median and Sex Ratio have less columns (every 5 years)\n",
        "   2.- Total population has an estimation for 2030"
      ],
      "metadata": {
        "id": "YZKt6Mph8NOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next Tasks**\n",
        "1.   Remove sex-ratio_at_birth from directory (not clear how it helps)\n",
        "2.   Remove spaces from all CSV files, replace unknown by column mean values and save a new copy\n",
        "3.   Interpolate values for median dataframe and save to file\n",
        "4.   Drop the 2030 column from total population as store it as a label dataframe"
      ],
      "metadata": {
        "id": "bbesE3EZ8sqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function to remove spaces and replace '..' with -1\n",
        "def clean(df):\n",
        "  # We need to remove spaces from the dataframe prior to interpolation\n",
        "  # And also to replace the unknown values (expressed as two consecutive points)\n",
        "  # to an arbitrary value of -1\n",
        "  # Finally we will convert the values to float\n",
        "  for col in df.columns:\n",
        "    df[col] = df[col].astype(str).str.strip().replace('..','-1')\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "JOwBgDHj8muH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to set the columns type\n",
        "def set_column_type(df, type, inclusive=None, exclusive=None):\n",
        "\n",
        "  cols = df.columns\n",
        "  if inclusive == None:\n",
        "    cols = [col for col in cols if not(col in exclusive)]\n",
        "  else:\n",
        "    cols = [col for col in cols if (col in inclusive)]\n",
        "\n",
        "  for col in cols:\n",
        "    df[col] = df[col].astype(float)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "OTx1xxfu9fPE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to replace unknown values by mean values for that year\n",
        "def replace_unknown_by_mean(df):\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == 'float64':\n",
        "      mean_value = np.round(df[df[col] != -1][col].mean(), 1)\n",
        "      df[col] = df[col].replace(-1.0, mean_value)\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "r_HW1iXCE-uy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to create interpolated columns\n",
        "def interpolate_columns(df, new_cols):\n",
        "  \n",
        "  def interpolate (y1, y2, x1, x2, x):\n",
        "    return np.round(y1 + (y2-y1)/(x2-x1) * (x-x1), 1)\n",
        "\n",
        "  for col in new_cols:\n",
        "    if not (col in df.columns):\n",
        "      # Adding a new column and creating the interpolation\n",
        "      year = int(col)\n",
        "      prev_year = year - year % 5\n",
        "      next_year = prev_year + 5\n",
        "\n",
        "      df[col] = np.vectorize(interpolate)(df[str(prev_year)], df[str(next_year)], prev_year, next_year, year)\n",
        "\n",
        "  sorted_df = df[['HDI Rank', 'Country']]\n",
        "  for col in new_cols:\n",
        "    sorted_df[col] = df[col]\n",
        "\n",
        "  return sorted_df"
      ],
      "metadata": {
        "id": "eCfQnqW9J1o8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Removing sex-ratio-at-birth\n",
        "os.remove('./raw_data/Sex_ratio_at_birth.csv')\n",
        "\n",
        "csv_file_list, csv_full_path_list = generate_file_list_from_dir(path=_RAW_DATA_DIR, filter = '.csv', display=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr0P9Z9S90P3",
        "outputId": "e2ee8e1e-2ff7-46b8-84bb-d1dfe722dbc8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Old_age_dependency_ratio.csv', 'Young_age_dependency_ratio.csv', 'Urban_Population.csv', 'Population_ages_15_64.csv', 'Median_age.csv', 'Population_under_age_5.csv', 'Total_Population.csv', 'Population _ages_65 _and _older.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Remove spaces from all CSV files, replace unknown by column mean values and save a new copy\n",
        "for file in csv_full_path_list:\n",
        "  df = pd.read_csv(file)\n",
        "  df = clean(df)\n",
        "  df = set_column_type(df, type='float', exclusive=['HDI Rank', 'Country'])\n",
        "  df = replace_unknown_by_mean(df)\n",
        "  df.to_csv(file, index=False)"
      ],
      "metadata": {
        "id": "6CKexW4n_Qxz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Interpolate values for median_age dataframe and save to file\n",
        "df = pd.read_csv('./raw_data/Median_age.csv')\n",
        "\n",
        "new_cols = ['1990', '1995', '2000', '2005', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
        "df = interpolate_columns(df, new_cols)\n",
        "df.to_csv('./raw_data/Median_age.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc_Br6Re2KRf",
        "outputId": "bde0d538-c9e3-4016-808c-cc98c904cbbc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 - Drop the 2030 column from total population as store it as a label dataframe\n",
        "df = pd.read_csv('./raw_data/Total_Population.csv')\n",
        "\n",
        "y_pop_2030 = df[['HDI Rank', 'Country']]\n",
        "y_pop_2030['2030'] = df['2030']\n",
        "df = df.drop('2030', axis=1)\n",
        "\n",
        "df.to_csv('./raw_data/Total_Population.csv', index=False)\n",
        "y_pop_2030.to_csv('./processed_data/y_pop_2030.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOTeLH-d8Fhh",
        "outputId": "8f204305-cd82-4421-cbbd-fb60d2fbee5c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file in csv_full_path_list:\n",
        "  temp_df = pd.read_csv(file)\n",
        "  print (f\"csv file: {file} - columns: {temp_df.columns}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbWEzo3_fqSk",
        "outputId": "83bb41e3-10b7-46a1-c48f-ac82cbc0ece6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv file: ./raw_data/Old_age_dependency_ratio.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Young_age_dependency_ratio.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Urban_Population.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population_ages_15_64.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Median_age.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population_under_age_5.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Total_Population.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population _ages_65 _and _older.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next Task**\n",
        "1.   Merge all the dataframes into one and save into the processed_data directory\n",
        "\n"
      ],
      "metadata": {
        "id": "A7woyyFLbVbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Merge all the dataframes into one and save into the processed_data directory\n",
        "res_df = None\n",
        "for file in csv_full_path_list:\n",
        "  df = pd.read_csv(file)\n",
        "  df = df.set_index('Country')\n",
        "  df = df.drop('HDI Rank', axis=1)\n",
        "  cols = df.columns\n",
        "  new_cols = [col+\"-\"+os.path.split(file)[1].replace('.csv',\"\") for col in cols]\n",
        "  df.columns = new_cols\n",
        "\n",
        "  if type(res_df) == type(None):\n",
        "    res_df = df\n",
        "  else:\n",
        "    res_df = pd.merge(res_df, df, how='outer', on='Country')\n",
        "\n",
        "res_df.to_csv('./processed_data/UNDP_Demographics_Data.csv', index=False)"
      ],
      "metadata": {
        "id": "4lL8wnBvcso9"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}
