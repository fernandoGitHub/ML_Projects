{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNDP_Demographics_Data-Analysis-Part_01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhq+Z3y5IG9ColVXpX3lLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandoGitHub/ML_Projects/blob/main/UNDP_Demographics_Data/UNDP_Demographics_Data_Analysis-Part_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **UNDP_Demographics_Data-Analysis-Part_01**\n",
        "\n",
        "This notebook will exercise working with several csv files while focusing on cleaning, cleansing and complete missing values using dataframe functionality only"
      ],
      "metadata": {
        "id": "A84hQ90Um8TY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "HNu8v-HprdvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pprint\n",
        "\n",
        "pp = pprint.PrettyPrinter()"
      ],
      "metadata": {
        "id": "x_i_KN4KrsT8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "rHiOu2jysJvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions for cleaning entire directories and create dir\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def clean_dir(path):\n",
        "  if os.path.isdir(path):\n",
        "    shutil.rmtree(path)\n",
        "\n",
        "def create_dir(path):\n",
        "  if not os.path.isdir(path):\n",
        "    os.makedirs(path)"
      ],
      "metadata": {
        "id": "4phiecPmzUw0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the scenario\n",
        "_RAW_DATA_DIR = './raw_data'\n",
        "_PROCESSED_DATA_DIR = './processed_data'\n",
        "\n",
        "clean_dir(_RAW_DATA_DIR)\n",
        "clean_dir(_PROCESSED_DATA_DIR)\n",
        "clean_dir('./sample_data')"
      ],
      "metadata": {
        "id": "Ry61HFKdy8WJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_RAW_DATA_ZIP = os.path.join(_RAW_DATA_DIR, 'UNDP_Demographics_Data.zip')\n",
        "\n",
        "create_dir(_RAW_DATA_DIR)\n",
        "create_dir(_PROCESSED_DATA_DIR)\n",
        "\n",
        "if not os.path.isfile(_RAW_DATA_ZIP):\n",
        "  !wget -O ./raw_data/UNDP_Demographics_Data.zip https://github.com/fernandoGitHub/ML_Projects/raw/main/UNDP_Demographics_Data/data/UNDP_Demographics_Data.zip"
      ],
      "metadata": {
        "id": "BpPOuGqLsMpO",
        "outputId": "60d3cda6-9cd9-4fe1-da85-8c15a1a8f621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-18 11:49:09--  https://github.com/fernandoGitHub/ML_Projects/raw/main/UNDP_Demographics_Data/data/UNDP_Demographics_Data.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fernandoGitHub/ML_Projects/main/UNDP_Demographics_Data/data/UNDP_Demographics_Data.zip [following]\n",
            "--2022-05-18 11:49:09--  https://raw.githubusercontent.com/fernandoGitHub/ML_Projects/main/UNDP_Demographics_Data/data/UNDP_Demographics_Data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44345 (43K) [application/zip]\n",
            "Saving to: ‘./raw_data/UNDP_Demographics_Data.zip’\n",
            "\n",
            "./raw_data/UNDP_Dem 100%[===================>]  43.31K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-05-18 11:49:09 (32.5 MB/s) - ‘./raw_data/UNDP_Demographics_Data.zip’ saved [44345/44345]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "zip_file_name = _RAW_DATA_ZIP\n",
        "\n",
        "with ZipFile(zip_file_name, 'r') as zip:\n",
        "  # printing all the contents of the zip file\n",
        "  zip.printdir()\n",
        "\n",
        "  # extracting all the files\n",
        "  zip.extractall(_RAW_DATA_DIR)"
      ],
      "metadata": {
        "id": "ViUmSG8LvlOD",
        "outputId": "abf112c7-af29-4e38-9516-2ee1587e34e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "Median_age.csv                                 2022-05-13 15:11:54         9288\n",
            "Old_age_dependency_ratio.csv                   2022-05-13 15:11:54        14159\n",
            "Population _ages_65 _and _older.csv            2022-05-13 15:11:54        12651\n",
            "Population_ages_15_64.csv                      2022-05-13 15:11:54        14059\n",
            "Population_under_age_5.csv                     2022-05-13 15:11:54        12955\n",
            "Sex_ratio_at_birth.csv                         2022-05-13 15:11:54         9570\n",
            "Total_Population.csv                           2022-05-13 15:11:54        15523\n",
            "Urban_Population.csv                           2022-05-13 15:11:54        16114\n",
            "Young_age_dependency_ratio.csv                 2022-05-13 15:11:54        15756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation"
      ],
      "metadata": {
        "id": "ZkBwhAoMybIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's review the columnns at each dataset"
      ],
      "metadata": {
        "id": "W5JV65Pt6-qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_file_list_from_dir(path, filter = '*.*', display=False):\n",
        "  \"\"\"generate_list_from_dir(path, filter = '*.*', display=False) returns two lists of strings.\n",
        "  The first includes the names of the csv files, the second the full paths. The filter parameter\n",
        "  can be used to return only a given type of files.\n",
        "  By default, the function doesn't filter any file\"\"\"\n",
        "\n",
        "  file_list = os.listdir(path=path)\n",
        "\n",
        "  if filter != '*.*':\n",
        "    file_list = [file for file in file_list if filter in file]\n",
        "\n",
        "  full_path_list = [os.path.join(path, file) for file in file_list]\n",
        "\n",
        "  if display:\n",
        "    print(file_list)\n",
        "\n",
        "  return file_list, full_path_list\n"
      ],
      "metadata": {
        "id": "pIbmb_soYeKG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_list, csv_full_path_list = generate_file_list_from_dir(path=_RAW_DATA_DIR, filter = '.csv', display=False)\n",
        "\n",
        "for file in csv_full_path_list:\n",
        "  temp_df = pd.read_csv(file)\n",
        "  print (f\"csv file: {file} - columns: {temp_df.columns}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJPE7K487EQl",
        "outputId": "db738a6f-479a-4570-b840-99071263d240"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv file: ./raw_data/Old_age_dependency_ratio.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Young_age_dependency_ratio.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Urban_Population.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population_ages_15_64.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Median_age.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2015',\n",
            "       '2020'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population_under_age_5.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Total_Population.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2030'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Sex_ratio_at_birth.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2015',\n",
            "       '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population _ages_65 _and _older.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding:** We can see some irregularities:\n",
        "   1.- Median and Sex Ratio have less columns (every 5 years)\n",
        "   2.- Total population has an estimation for 2030"
      ],
      "metadata": {
        "id": "YZKt6Mph8NOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next Tasks**\n",
        "1.   Remove sex-ratio_at_birth from directory (not clear how it helps)\n",
        "2.   Remove spaces from all CSV files, replace unknown by column mean values and save a new copy\n",
        "3.   Interpolate values for median dataframe and save to file\n",
        "4.   Drop the 2030 column from total population as store it as a label dataframe"
      ],
      "metadata": {
        "id": "bbesE3EZ8sqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function to remove spaces and replace '..' with -1\n",
        "def clean(df):\n",
        "  # We need to remove spaces from the dataframe prior to interpolation\n",
        "  # And also to replace the unknown values (expressed as two consecutive points)\n",
        "  # to an arbitrary value of -1\n",
        "  # Finally we will convert the values to float\n",
        "  for col in df.columns:\n",
        "    df[col] = df[col].astype(str).str.strip().replace('..','-1')\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "JOwBgDHj8muH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to set the columns type\n",
        "def set_column_type(df, type, inclusive=None, exclusive=None):\n",
        "\n",
        "  cols = df.columns\n",
        "  if inclusive == None:\n",
        "    cols = [col for col in cols if not(col in exclusive)]\n",
        "  else:\n",
        "    cols = [col for col in cols if (col in inclusive)]\n",
        "\n",
        "  for col in cols:\n",
        "    df[col] = df[col].astype(float)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "OTx1xxfu9fPE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to replace unknown values by mean values for that year\n",
        "def replace_unknown_by_mean(df):\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == 'float64':\n",
        "      mean_value = np.round(df[df[col] != -1][col].mean(), 1)\n",
        "      df[col] = df[col].replace(-1.0, mean_value)\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "r_HW1iXCE-uy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to create interpolated columns\n",
        "def interpolate_columns(df, new_cols):\n",
        "  \n",
        "  def interpolate (y1, y2, x1, x2, x):\n",
        "    return np.round(y1 + (y2-y1)/(x2-x1) * (x-x1), 1)\n",
        "\n",
        "  for col in new_cols:\n",
        "    if not (col in df.columns):\n",
        "      # Adding a new column and creating the interpolation\n",
        "      year = int(col)\n",
        "      prev_year = year - year % 5\n",
        "      next_year = prev_year + 5\n",
        "\n",
        "      df[col] = np.vectorize(interpolate)(df[str(prev_year)], df[str(next_year)], prev_year, next_year, year)\n",
        "\n",
        "  sorted_df = pd.DataFrame(index=df.index, columns=new_cols)\n",
        "  for col in new_cols:\n",
        "    sorted_df[col] = df[col]\n",
        "\n",
        "  return sorted_df"
      ],
      "metadata": {
        "id": "eCfQnqW9J1o8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Removing sex-ratio-at-birth\n",
        "os.remove('./raw_data/Sex_ratio_at_birth.csv')\n",
        "\n",
        "csv_file_list, csv_full_path_list = generate_file_list_from_dir(path=_RAW_DATA_DIR, filter = '.csv', display=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr0P9Z9S90P3",
        "outputId": "f7c00024-7a9f-4b51-aa61-262d1c4a109b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Old_age_dependency_ratio.csv', 'Young_age_dependency_ratio.csv', 'Urban_Population.csv', 'Population_ages_15_64.csv', 'Median_age.csv', 'Population_under_age_5.csv', 'Total_Population.csv', 'Population _ages_65 _and _older.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Remove spaces from all CSV files, replace unknown by column mean values and save a new copy\n",
        "for file in csv_file_list:\n",
        "  df = pd.read_csv(os.path.join(_RAW_DATA_DIR, file))\n",
        "  df = df.drop('HDI Rank', axis = 1)\n",
        "  df = df.set_index('Country')\n",
        "  df = clean(df)\n",
        "  df = set_column_type(df, type='float',exclusive=['Country'])\n",
        "  df = replace_unknown_by_mean(df)\n",
        "\n",
        "  df.to_csv(os.path.join(_PROCESSED_DATA_DIR, file), index=True)"
      ],
      "metadata": {
        "id": "6CKexW4n_Qxz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Interpolate values for median_age dataframe and save to file\n",
        "df = pd.read_csv(os.path.join(_PROCESSED_DATA_DIR, 'Median_age.csv'))\n",
        "df = df.set_index('Country')\n",
        "\n",
        "new_cols = ['1990', '1995', '2000', '2005', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
        "df = interpolate_columns(df, new_cols)\n",
        "df.to_csv(os.path.join(_PROCESSED_DATA_DIR, 'Median_age.csv'), index=True)"
      ],
      "metadata": {
        "id": "tc_Br6Re2KRf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 - Drop the 2030 column from total population as store it as a label dataframe\n",
        "df = pd.read_csv('./raw_data/Total_Population.csv')\n",
        "df = df.set_index('Country')\n",
        "\n",
        "y_pop_2030 = df['2030']\n",
        "df = df.drop('2030', axis=1)\n",
        "\n",
        "df.to_csv('./raw_data/Total_Population.csv', index=True)\n",
        "y_pop_2030.to_csv('./processed_data/y_pop_2030.csv', index=True)"
      ],
      "metadata": {
        "id": "JOTeLH-d8Fhh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in csv_full_path_list:\n",
        "  temp_df = pd.read_csv(file)\n",
        "  print (f\"csv file: {file} - columns: {temp_df.columns}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbWEzo3_fqSk",
        "outputId": "4d72f52f-d8c5-4550-a262-7620f251c018"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv file: ./raw_data/Old_age_dependency_ratio.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Young_age_dependency_ratio.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Urban_Population.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population_ages_15_64.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Median_age.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2015',\n",
            "       '2020'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population_under_age_5.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Total_Population.csv - columns: Index(['Country', 'HDI Rank', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n",
            "csv file: ./raw_data/Population _ages_65 _and _older.csv - columns: Index(['HDI Rank', 'Country', '1990', '1995', '2000', '2005', '2010', '2011',\n",
            "       '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next Task**\n",
        "1.   Merge all the dataframes into one and save into the processed_data directory\n",
        "\n"
      ],
      "metadata": {
        "id": "A7woyyFLbVbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Merge all the dataframes into one and save into the processed_data directory\n",
        "res_df = None\n",
        "for file in csv_file_list:\n",
        "  df = pd.read_csv(os.path.join(_PROCESSED_DATA_DIR, file))\n",
        "  df = df.set_index('Country')\n",
        "  cols = df.columns\n",
        "  new_cols = [col+\"-\"+os.path.split(file)[1].replace('.csv',\"\") for col in cols]\n",
        "  df.columns = new_cols\n",
        "\n",
        "  if type(res_df) == type(None):\n",
        "    res_df = df\n",
        "  else:\n",
        "    res_df = pd.merge(res_df, df, how='outer', on='Country')\n",
        "\n",
        "# Dropping partial rows\n",
        "res_df = res_df.dropna(axis=0)\n",
        "\n",
        "res_df.to_csv('./processed_data/UNDP_Demographics_Data.csv', index=True)"
      ],
      "metadata": {
        "id": "4lL8wnBvcso9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('./UNDP-Processed', 'zip', _PROCESSED_DATA_DIR)"
      ],
      "metadata": {
        "id": "Ez95kKaj9kd2",
        "outputId": "d10940d8-a329-4b1c-a338-dcba4bb0aad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/UNDP-Processed.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}